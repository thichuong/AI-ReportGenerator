"""
Node Ä‘á»ƒ soáº¡n ná»™i dung bÃ¡o cÃ¡o markdown tá»« ná»™i dung nghiÃªn cá»©u
"""
from google.genai import types
from .base import ReportState, read_prompt_file, get_prompt_from_env, call_gemini_with_rate_limit_handling
from ...services.progress_tracker import progress_tracker


def generate_report_content_node(state: ReportState) -> ReportState:
    """Node Ä‘á»ƒ chuyá»ƒn ná»™i dung nghiÃªn cá»©u thÃ nh bÃ¡o cÃ¡o phÃ¢n tÃ­ch chuyÃªn sÃ¢u (markdown)"""
    session_id = state["session_id"]

    # CHECK RATE LIMIT FLAG - Skip node if already hit rate limit
    if state.get("rate_limit_stop"):
        print(f"â›” [{session_id}] Skipping generate_report_content - rate limit flag is set")
        return state

    attempt_key = "report_attempt"
    if attempt_key not in state:
        state[attempt_key] = 0
    state[attempt_key] += 1

    # BÆ°á»›c soáº¡n ná»™i dung bÃ¡o cÃ¡o
    progress_tracker.update_step(
        session_id,
        4,
        f"Soáº¡n ná»™i dung bÃ¡o cÃ¡o (láº§n {state[attempt_key]})",
        "Táº¡o ná»™i dung bÃ¡o cÃ¡o markdown"
    )

    # Äá»c prompt soáº¡n bÃ¡o cÃ¡o tá»« biáº¿n mÃ´i trÆ°á»ng
    prompt = get_prompt_from_env('generate_report')
    if not prompt:
        error_msg = "KhÃ´ng thá»ƒ Ä‘á»c prompt soáº¡n bÃ¡o cÃ¡o tá»« biáº¿n mÃ´i trÆ°á»ng"
        state["error_messages"].append(error_msg)
        state["success"] = False
        progress_tracker.error_progress(session_id, error_msg)
        return state

    # Táº¡o request Ä‘á»ƒ soáº¡n bÃ¡o cÃ¡o
    research_content = state.get("research_content", "")
    full_request = prompt.replace("{content}", research_content)

    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text=full_request),
            ],
        ),
    ]

    config = types.GenerateContentConfig(
        temperature=0.5,
        candidate_count=1,
        max_output_tokens=25000,
        thinking_config=types.ThinkingConfig(
            thinking_budget=4096,
        ),
    )

    # Call API with centralized error handler
    progress_tracker.update_step(session_id, details="Gá»i AI soáº¡n bÃ¡o cÃ¡o...")
    response, error_msg, is_rate_limit = call_gemini_with_rate_limit_handling(
        client=state["client"],
        model=state["model"],
        contents=contents,
        config=config,
        session_id=session_id,
        operation_name="generate_report_content",
        max_retries=3
    )

    # Check for rate limit error - stop immediately
    if is_rate_limit:
        state["error_messages"].append(error_msg)
        state["success"] = False
        state["rate_limit_stop"] = True  # SET FLAG to stop workflow
        progress_tracker.error_progress(session_id, "ğŸš« Rate limit error - Ä‘Ã£ set flag dá»«ng workflow")
        print(f"â›” [{session_id}] rate_limit_stop flag SET - workflow will terminate")
        return state

    # Check for other errors after retries
    if error_msg:
        state["error_messages"].append(error_msg)
        state["success"] = False
        progress_tracker.error_progress(session_id, error_msg)
        return state

    # Kiá»ƒm tra response
    if not response or not hasattr(response, 'text') or not response.text:
        error_msg = "KhÃ´ng nháº­n Ä‘Æ°á»£c ná»™i dung bÃ¡o cÃ¡o tá»« AI"
        state["error_messages"].append(error_msg)
        state["success"] = False
        progress_tracker.error_progress(session_id, error_msg)
        return state

    report_md = response.text.strip()
    state["report_content"] = report_md
    state["success"] = True
    progress_tracker.update_step(session_id, details=f"âœ“ Soáº¡n bÃ¡o cÃ¡o hoÃ n thÃ nh - {len(report_md)} chars")

    # ğŸ§¹ Memory cleanup - giáº£i phÃ³ng temporary large objects
    del full_request  # XÃ³a prompt + research_content (cÃ³ thá»ƒ 50KB+)
    del contents  # XÃ³a request contents
    del response  # XÃ³a response object
    del report_md  # XÃ³a temporary variable (Ä‘Ã£ lÆ°u vÃ o state)
    import gc
    gc.collect()
    print("ğŸ§¹ [generate_report] Memory cleanup completed")

    return state
