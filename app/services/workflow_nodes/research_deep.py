"""
Node th·ª±c hi·ªán nghi√™n c·ª©u s√¢u + validation
"""
import json
from google.genai import types
from .base import ReportState, check_report_validation, call_gemini_with_rate_limit_handling
from ...services.progress_tracker import progress_tracker


def research_deep_node(state: ReportState) -> ReportState:
    """Node ƒë·ªÉ th·ª±c hi·ªán nghi√™n c·ª©u s√¢u + validation v·ªõi Google Search v√† real-time data trong 1 l·∫ßn g·ªçi"""
    session_id = state["session_id"]

    # CHECK RATE LIMIT FLAG - Skip node if already hit rate limit
    if state.get("rate_limit_stop"):
        print(f"‚õî [{session_id}] Skipping research_deep - rate limit flag is set")
        return state

    # Initialize current_attempt if not exists
    if "current_attempt" not in state:
        state["current_attempt"] = 0
    state["current_attempt"] += 1
    
    progress_tracker.update_step(session_id, 2, f"Research + Validation (l·∫ßn {state['current_attempt']})", 
                               "C·∫•u h√¨nh AI tools, Google Search v√† th·ª±c hi·ªán combined research + validation")
    
    try:
        # Chu·∫©n b·ªã combined prompt v·ªõi real-time data
        combined_prompt = state["research_analysis_prompt"]
        
        # Th√™m real-time data v√†o prompt
        realtime_data = state.get("realtime_data")
        if realtime_data:
            # Inject real-time data v√†o combined prompt
            combined_prompt = combined_prompt.replace(
                "{{REAL_TIME_DATA}}", 
                json.dumps(realtime_data, ensure_ascii=False, indent=2)
            )
            progress_tracker.update_step(session_id, details="‚úì ƒê√£ inject real-time data v√†o combined prompt")
        else:
            # Thay th·∫ø b·∫±ng fallback message
            combined_prompt = combined_prompt.replace(
                "{{REAL_TIME_DATA}}", 
                "{\n  \"notice\": \"Real-time data kh√¥ng kh·∫£ d·ª•ng, s·ª≠ d·ª•ng Google Search ƒë·ªÉ l·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t\"\n}"
            )
            progress_tracker.update_step(session_id, details="‚ö†Ô∏è Kh√¥ng c√≥ real-time data, s·ª≠ d·ª•ng Google Search")
        
        # C·∫•u h√¨nh tools v·ªõi thinking budget cao h∆°n cho combined task
        tools = [
            types.Tool(googleSearch=types.GoogleSearch()),
        ]
        generate_content_config = types.GenerateContentConfig(
            thinking_config=types.ThinkingConfig(
                thinking_budget=8192,  # Gi·∫£m thinking xu·ªëng ~8k-10k ƒë·ªÉ d√†nh ƒë·∫•t cho n·ªôi dung
            ),
            tools=tools,
            temperature=0.7,
            candidate_count=1,
            max_output_tokens=60000,
        )
        
        # T·∫°o request content v·ªõi combined prompt
        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=combined_prompt),
                ],
            ),
        ]
        
        # G·ªçi API 3 l·∫ßn ƒë·ªÉ c√≥ 3 response kh√°c nhau (do model kh√¥ng h·ªó tr·ª£ multiple candidates)
        all_responses = []

        for call_attempt in range(1):
            progress_tracker.update_step(session_id, details=f"G·ªçi Combined AI API l·∫ßn {call_attempt + 1}/3...")

            # Use centralized error handler
            response, error_msg, is_rate_limit = call_gemini_with_rate_limit_handling(
                client=state["client"],
                model=state["model"],
                contents=contents,
                config=generate_content_config,
                session_id=session_id,
                operation_name=f"research_deep_call_{call_attempt + 1}",
                max_retries=3
            )

            # Check for rate limit error - stop immediately
            if is_rate_limit:
                state["error_messages"].append(error_msg)
                state["success"] = False
                state["rate_limit_stop"] = True  # SET FLAG to stop workflow
                progress_tracker.update_step(session_id, details=f"üö´ Rate limit error - ƒë√£ set flag d·ª´ng workflow")
                print(f"‚õî [{session_id}] rate_limit_stop flag SET - workflow will terminate")
                return state

            # Check for other errors after retries
            if error_msg:
                progress_tracker.update_step(session_id, details=f"L·ªói API call {call_attempt + 1} sau 3 l·∫ßn th·ª≠: {error_msg}")
                response = None

            # Ki·ªÉm tra v√† l∆∞u response
            if response and hasattr(response, 'text') and response.text:
                all_responses.append(f"=== RESPONSE {call_attempt + 1} ===\n{response.text}\n")
                progress_tracker.update_step(session_id, details=f"‚úì Th√†nh c√¥ng API call {call_attempt + 1}/3")
            else:
                progress_tracker.update_step(session_id, details=f"‚úó Kh√¥ng nh·∫≠n ƒë∆∞·ª£c response h·ª£p l·ªá t·ª´ call {call_attempt + 1}")
        
        # Ki·ªÉm tra c√≥ √≠t nh·∫•t 1 response th√†nh c√¥ng
        if not all_responses:
            error_msg = f"L·∫ßn th·ª≠ {state['current_attempt']}: Kh√¥ng nh·∫≠n ƒë∆∞·ª£c response h·ª£p l·ªá t·ª´ b·∫•t k·ª≥ API call n√†o"
            state["error_messages"].append(error_msg)
            progress_tracker.update_step(session_id, details=error_msg)
            state["success"] = False
            return state
        
        # K·∫øt h·ª£p t·∫•t c·∫£ responses
        full_response_text = "\n".join(all_responses)
        
        # Parse combined response ƒë·ªÉ extract research content v√† validation result
        progress_tracker.update_step(session_id, details=f"Parsing combined response v·ªõi {len(all_responses)} responses...")
        
        # T√¨m validation result trong to√†n b·ªô combined response
        validation_result = check_report_validation(full_response_text)
        state["validation_result"] = validation_result
        
        state["research_content"] = full_response_text
        
        # Set success based on validation result
        if validation_result == "PASS":
            state["success"] = True
            progress_tracker.update_step(session_id, details=f"‚úì Combined Research + Validation PASS")
        elif validation_result == "FAIL":
            state["success"] = False
            progress_tracker.update_step(session_id, details=f"‚úó Combined Research + Validation FAIL")
        else:
            # UNKNOWN validation result - treat as success but log warning
            state["success"] = True
            state["validation_result"] = "UNKNOWN"
            progress_tracker.update_step(session_id, details=f"? Combined Response v·ªõi validation UNKNOWN")
        
        # Log response length for debugging
        progress_tracker.update_step(session_id, details=
            f"‚úì Combined response: {len(full_response_text)} chars t·ª´ {len(all_responses)} responses, "
            f"validation: {validation_result}")
        
        # üßπ Memory cleanup - gi·∫£i ph√≥ng temporary large objects
        del all_responses  # X√≥a list ch·ª©a 3 response texts l·ªõn
        del full_response_text  # X√≥a combined text (ƒë√£ l∆∞u v√†o state["research_content"])
        import gc
        gc.collect()
        print("üßπ [research_deep] Memory cleanup completed")
        
    except Exception as e:
        error_msg = f"L·∫ßn th·ª≠ {state['current_attempt']}: L·ªói khi g·ªçi Combined AI: {e}"
        state["error_messages"].append(error_msg)
        progress_tracker.update_step(session_id, details=error_msg)
        state["success"] = False
        
        # üßπ Memory cleanup ngay c·∫£ khi c√≥ l·ªói
        import gc
        gc.collect()
    
    return state
