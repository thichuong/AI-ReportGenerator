"""
Node táº¡o giao diá»‡n tá»« bÃ¡o cÃ¡o nghiÃªn cá»©u
"""
import re
from google.genai import types
from .base import ReportState, read_prompt_file, get_prompt_from_env, call_gemini_with_rate_limit_handling
from ...services.progress_tracker import progress_tracker


def create_interface_node(state: ReportState) -> ReportState:
    """Node Ä‘á»ƒ táº¡o giao diá»‡n tá»« bÃ¡o cÃ¡o nghiÃªn cá»©u"""
    session_id = state["session_id"]
    interface_attempt_key = "interface_attempt"
    if interface_attempt_key not in state:
        state[interface_attempt_key] = 0
    state[interface_attempt_key] += 1
    
    progress_tracker.update_step(session_id, 5, f"Táº¡o giao diá»‡n (láº§n {state[interface_attempt_key]})", "Chuáº©n bá»‹ táº¡o HTML, CSS, JS")
    report_md = state.get('report_content') or state.get('research_content', '')
    create_report_prompt = get_prompt_from_env('create_report')
    # Táº¡o request Ä‘áº§y Ä‘á»§
    full_request = f"{create_report_prompt}\n\n---\n\n**Ná»˜I DUNG BÃO CÃO Cáº¦N Xá»¬ LÃ:**\n\n{report_md}"
    
    interface_contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text=full_request),
            ],
        ),
    ]
    
    simple_config = types.GenerateContentConfig(
        temperature=0,
        candidate_count=1,
    )
    
    # Call API with centralized error handler
    progress_tracker.update_step(session_id, details="Gá»i AI táº¡o giao diá»‡n...")
    interface_response, error_msg, is_rate_limit = call_gemini_with_rate_limit_handling(
        client=state["client"],
        model=state["model"],
        contents=interface_contents,
        config=simple_config,
        session_id=session_id,
        operation_name="create_interface",
        max_retries=3
    )

    # Check for rate limit error - stop immediately
    if is_rate_limit:
        state["error_messages"].append(error_msg)
        state["success"] = False
        progress_tracker.error_progress(session_id, "ğŸš« Rate limit error - dá»«ng workflow ngay láº­p tá»©c")
        return state

    # Check for other errors after retries
    if error_msg:
        state["error_messages"].append(error_msg)
        state["success"] = False
        progress_tracker.error_progress(session_id, error_msg)
        return state
    
    # Kiá»ƒm tra interface response
    if not interface_response or not hasattr(interface_response, 'text'):
        error_msg = "Interface response khÃ´ng há»£p lá»‡ tá»« AI"
        state["error_messages"].append(error_msg)
        state["success"] = False
        progress_tracker.error_progress(session_id, error_msg)
        return state
        
    if not interface_response.text:
        error_msg = "KhÃ´ng nháº­n Ä‘Æ°á»£c ná»™i dung interface tá»« AI"
        state["error_messages"].append(error_msg)
        state["success"] = False
        progress_tracker.error_progress(session_id, error_msg)
        return state
    
    state["interface_content"] = interface_response.text
    state["success"] = True
    progress_tracker.update_step(session_id, details="âœ“ Táº¡o giao diá»‡n hoÃ n thÃ nh")
    
    # ğŸ§¹ Memory cleanup - giáº£i phÃ³ng temporary large objects
    del full_request  # XÃ³a prompt + report content (cÃ³ thá»ƒ 100KB+)
    del interface_contents  # XÃ³a request contents
    del interface_response  # XÃ³a response object vá»›i HTML/CSS/JS
    import gc
    gc.collect()
    print("ğŸ§¹ [create_interface] Memory cleanup completed")
    
    return state
